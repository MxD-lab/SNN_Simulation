{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neralnetwork仮.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MxD-lab/SNN_Simulation/blob/neralnetwork/neralnetwork%E4%BB%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDoqQNyWTZA4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmHemqNMVycT"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy \n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVfiDGT0TSiz"
      },
      "source": [
        "#シグモイド関数（出力層）\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#ReLU関数（隠れ層）\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtffoYMfTPc1"
      },
      "source": [
        "#交差エントロピー誤差\n",
        "\n",
        "def cross_entropy_error(y,t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1,t.size)\n",
        "    y = y.reshape(1,y.size)\n",
        "  \n",
        "  batch_size = y.shape[0]#yの行数\n",
        "  return np.sum(-t*np.log(y)-(1-t)*np.log(1-y))/batch_size\n",
        "\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2vL9vh16z4r"
      },
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM8pe9UDRs3V"
      },
      "source": [
        "\"\"\"\n",
        "重み、バイアス、初期設定\n",
        "W1：隠れ層の重み\n",
        "B1:隠れ層のバイアス\n",
        "W2:出力層の重み\n",
        "B2:隠れ層のバイアス\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "W1 = np.array([[0.707760268819045,-0.83735145624508],[-1.21179516971129,-0.426362970984348]])\n",
        "B1 = np.array([-0.311592487617895,0.46169885478039])\n",
        "W2 = np.array([[0.539158501953791],[-0.41755354864446]])\n",
        "B2 = np.array([0.141883319414468])\n",
        "#print(W1)\n",
        "\"\"\"\n",
        "\n",
        "W1 = np.random.rand(2,2)\n",
        "B1 = np.random.rand(2)\n",
        "W2 = np.random.rand(2,1)\n",
        "B2 = np.random.rand(1)\n",
        "#print(W1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IObJ4TdZvMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3e143336-d54a-4ac0-f8b8-aed22dab9139"
      },
      "source": [
        "#活性化関数の微分(relu)u:隠れ層の活性\n",
        "\n",
        "def relu_diff(u):\n",
        "  d = np.zeros_like(u) #xと同じ形状の配列を作成\n",
        "  for i in range(len(u)):\n",
        "    for j in range(len(u[0])):\n",
        "      if u[i][j]>0:\n",
        "        d[i][j] = 1\n",
        "      else: \n",
        "        d[i][j] = 0\n",
        "\n",
        "  return d\n",
        "\n",
        "\"\"\"\n",
        "def relu_diff(u):\n",
        "  d = np.where( x > 0, 1, 0)\n",
        "  return y\n",
        "\"\"\""
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef relu_diff(u):\\n  d = np.where( x > 0, 1, 0)\\n  return y\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYNn0omkegSu"
      },
      "source": [
        "#隠れ層の誤差\n",
        "\"\"\"\n",
        "delta:一個前の誤差（出力層の誤差）\n",
        "w:一個前の重み（出力層の重み）\n",
        "activ:活性化関数の微分\n",
        "\"\"\"\n",
        "def hidden_delta(delta,w,activ):\n",
        "  d = np.zeros((4,2)) #データ数×隠れ層のニューロン数の配列を作成\n",
        "  #d = np.zeros((int(delta),int(w[0])))\n",
        "  for i in range(len(delta)):\n",
        "    for j in range(len(w[0])):\n",
        "      d[i][j] = delta[i]*w[j]*activ[i][j]\n",
        "  return np.array(d)\n",
        "  "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyTzwOuZ8DZv"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZSLLE7KUrlt",
        "outputId": "3ea03bdf-6e4c-4564-ad56-b7a12919a40d"
      },
      "source": [
        "\n",
        "i = 0\n",
        "y = np.zeros(300)\n",
        "\n",
        "N = 4#データ数(ミニバッチ)\n",
        "learning_rate = 0.2#学習率\n",
        "for i in range(300):\n",
        "  \n",
        "  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\n",
        "  target =  np.array([[0],[1],[1],[0]]) #教師\n",
        "  \n",
        "\n",
        "  A1 = np.dot(x,W1)+B1\n",
        "  Z1 = relu(A1)#一層目活性化関数かける\n",
        "  A2 = np.dot(Z1,W2) + B2\n",
        "  Z2 = sigmoid(A2)\n",
        "  #print(\"Z1\")\n",
        "  #print(Z1)\n",
        "  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\n",
        "  \n",
        "  #print(y)\n",
        "\n",
        "  ###出力層の逆伝搬\n",
        "  ##重み\n",
        "  delta = Z2 - target#誤差\n",
        "  #print(Z2)\n",
        "  #print(\"delta\")\n",
        "  #print(delta)\n",
        "  Z1_t = np.transpose(Z1)\n",
        "  #print(Z1_t)\n",
        "  sum_delta = np.dot(Z1_t,delta)\n",
        "  #print(\"sum_delta\")\n",
        "  #print(sum_delta)\n",
        "  \n",
        "  #print(\"delta_out\")\n",
        "  #delta_out　なんか違う\n",
        "  delta_out =(1/N)*sum_delta\n",
        "  #print(\"delta_out\")\n",
        "  #print(delta_out)\n",
        "  \n",
        "  print(\"W2\")\n",
        "  print(W2)\n",
        " \n",
        "  W2 = W2 - learning_rate*delta_out\n",
        "  #print(\"W2\")\n",
        "  #print(W2)\n",
        "\n",
        "\n",
        "  ##バイアス\n",
        "  a = np.array([1,1,1,1])\n",
        "  sum_delta_bias = np.dot(a,delta)\n",
        "  delta_out_bias = 1/N*sum_delta_bias\n",
        "  #print(delta_out_bias)\n",
        "  #print(B2)\n",
        "  B2 = B2 - learning_rate*delta_out_bias\n",
        "  #print(\"B2\")\n",
        "  #print(B2)\n",
        "\n",
        "  ###隠れ層の逆伝搬\n",
        "  ##重み\n",
        "  differential_y = relu_diff(Z1)#活性化関数の微分\n",
        "  #print(differential_y)\n",
        "  hid_delta = hidden_delta(delta,W2,differential_y)\n",
        "  #print(hid_delta)\n",
        "  x_t = np.transpose(x)\n",
        "  delta_hidden = 1/N*np.dot(x_t,hid_delta)\n",
        "  W1 = W1 - learning_rate*delta_hidden\n",
        "  #print(\"W1\")\n",
        "  #print(W1)\n",
        "\n",
        "  ##バイアス\n",
        "  a2 = np.array([1,1,1,1])\n",
        "  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\n",
        "  #print(B1)\n",
        "  B1 = B1 - learning_rate*delta_hidden_bias\n",
        "  #print(\"B1\")\n",
        "  #print(B1)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2\n",
            "[[0.71113168]\n",
            " [0.74179485]]\n",
            "W2\n",
            "[[0.64517402]\n",
            " [0.6615012 ]]\n",
            "W2\n",
            "[[0.58880107]\n",
            " [0.58550104]]\n",
            "W2\n",
            "[[0.54075384]\n",
            " [0.51415063]]\n",
            "W2\n",
            "[[0.49989136]\n",
            " [0.44769117]]\n",
            "W2\n",
            "[[0.46519107]\n",
            " [0.38624304]]\n",
            "W2\n",
            "[[0.43574695]\n",
            " [0.32981024]]\n",
            "W2\n",
            "[[0.41076525]\n",
            " [0.27829341]]\n",
            "W2\n",
            "[[0.38955799]\n",
            " [0.23150858]]\n",
            "W2\n",
            "[[0.37153473]\n",
            " [0.18920852]]\n",
            "W2\n",
            "[[0.35619307]\n",
            " [0.15110373]]\n",
            "W2\n",
            "[[0.3431085 ]\n",
            " [0.11688118]]\n",
            "W2\n",
            "[[0.33192426]\n",
            " [0.08621965]]\n",
            "W2\n",
            "[[0.3223417 ]\n",
            " [0.05880143]]\n",
            "W2\n",
            "[[0.31388662]\n",
            " [0.03430643]]\n",
            "W2\n",
            "[[0.30639803]\n",
            " [0.01233699]]\n",
            "W2\n",
            "[[ 0.29977394]\n",
            " [-0.00735043]]\n",
            "W2\n",
            "[[ 0.29392658]\n",
            " [-0.0249826 ]]\n",
            "W2\n",
            "[[ 0.28870617]\n",
            " [-0.04077314]]\n",
            "W2\n",
            "[[ 0.28411825]\n",
            " [-0.05480585]]\n",
            "W2\n",
            "[[ 0.28003727]\n",
            " [-0.06737108]]\n",
            "W2\n",
            "[[ 0.2764429 ]\n",
            " [-0.07852661]]\n",
            "W2\n",
            "[[ 0.27322966]\n",
            " [-0.08852236]]\n",
            "W2\n",
            "[[ 0.27041945]\n",
            " [-0.0973878 ]]\n",
            "W2\n",
            "[[ 0.26790952]\n",
            " [-0.10525161]]\n",
            "W2\n",
            "[[ 0.26567685]\n",
            " [-0.11231009]]\n",
            "W2\n",
            "[[ 0.26371952]\n",
            " [-0.11856337]]\n",
            "W2\n",
            "[[ 0.26199214]\n",
            " [-0.12410198]]\n",
            "W2\n",
            "[[ 0.26042531]\n",
            " [-0.1290909 ]]\n",
            "W2\n",
            "[[ 0.25905059]\n",
            " [-0.13350428]]\n",
            "W2\n",
            "[[ 0.25784448]\n",
            " [-0.13740644]]\n",
            "W2\n",
            "[[ 0.25678656]\n",
            " [-0.14085449]]\n",
            "W2\n",
            "[[ 0.25585903]\n",
            " [-0.14389913]]\n",
            "W2\n",
            "[[ 0.25503609]\n",
            " [-0.14658598]]\n",
            "W2\n",
            "[[ 0.2542833]\n",
            " [-0.1490343]]\n",
            "W2\n",
            "[[ 0.25362486]\n",
            " [-0.15118991]]\n",
            "W2\n",
            "[[ 0.2530497 ]\n",
            " [-0.15308547]]\n",
            "W2\n",
            "[[ 0.2525481]\n",
            " [-0.15475  ]]\n",
            "W2\n",
            "[[ 0.25211153]\n",
            " [-0.15620929]]\n",
            "W2\n",
            "[[ 0.25173245]\n",
            " [-0.15748622]]\n",
            "W2\n",
            "[[ 0.25140424]\n",
            " [-0.15860115]]\n",
            "W2\n",
            "[[ 0.25112103]\n",
            " [-0.15957213]]\n",
            "W2\n",
            "[[ 0.25087766]\n",
            " [-0.16041524]]\n",
            "W2\n",
            "[[ 0.25066956]\n",
            " [-0.16114474]]\n",
            "W2\n",
            "[[ 0.25049269]\n",
            " [-0.16177332]]\n",
            "W2\n",
            "[[ 0.25034348]\n",
            " [-0.16231226]]\n",
            "W2\n",
            "[[ 0.25021876]\n",
            " [-0.16277158]]\n",
            "W2\n",
            "[[ 0.25011574]\n",
            " [-0.16316018]]\n",
            "W2\n",
            "[[ 0.25003191]\n",
            " [-0.163486  ]]\n",
            "W2\n",
            "[[ 0.24996132]\n",
            " [-0.16375629]]\n",
            "W2\n",
            "[[ 0.24988322]\n",
            " [-0.16405314]]\n",
            "W2\n",
            "[[ 0.24982149]\n",
            " [-0.16429722]]\n",
            "W2\n",
            "[[ 0.24977427]\n",
            " [-0.16449448]]\n",
            "W2\n",
            "[[ 0.24973986]\n",
            " [-0.16465021]]\n",
            "W2\n",
            "[[ 0.2497168 ]\n",
            " [-0.16476909]]\n",
            "W2\n",
            "[[ 0.24970376]\n",
            " [-0.1648553 ]]\n",
            "W2\n",
            "[[ 0.24969958]\n",
            " [-0.16491256]]\n",
            "W2\n",
            "[[ 0.24970322]\n",
            " [-0.16494416]]\n",
            "W2\n",
            "[[ 0.24971376]\n",
            " [-0.16495303]]\n",
            "W2\n",
            "[[ 0.24973038]\n",
            " [-0.16494179]]\n",
            "W2\n",
            "[[ 0.24975235]\n",
            " [-0.16491275]]\n",
            "W2\n",
            "[[ 0.24977903]\n",
            " [-0.16486797]]\n",
            "W2\n",
            "[[ 0.24980985]\n",
            " [-0.16480929]]\n",
            "W2\n",
            "[[ 0.2498443 ]\n",
            " [-0.16473833]]\n",
            "W2\n",
            "[[ 0.24988192]\n",
            " [-0.16465655]]\n",
            "W2\n",
            "[[ 0.24992231]\n",
            " [-0.16456523]]\n",
            "W2\n",
            "[[ 0.24996513]\n",
            " [-0.16446552]]\n",
            "W2\n",
            "[[ 0.25001005]\n",
            " [-0.16435843]]\n",
            "W2\n",
            "[[ 0.25005678]\n",
            " [-0.16424487]]\n",
            "W2\n",
            "[[ 0.25010509]\n",
            " [-0.16412565]]\n",
            "W2\n",
            "[[ 0.25015474]\n",
            " [-0.16400147]]\n",
            "W2\n",
            "[[ 0.25020555]\n",
            " [-0.16387297]]\n",
            "W2\n",
            "[[ 0.25025733]\n",
            " [-0.16374072]]\n",
            "W2\n",
            "[[ 0.25030993]\n",
            " [-0.16360522]]\n",
            "W2\n",
            "[[ 0.25036322]\n",
            " [-0.16346691]]\n",
            "W2\n",
            "[[ 0.25041707]\n",
            " [-0.16332619]]\n",
            "W2\n",
            "[[ 0.25047137]\n",
            " [-0.16318342]]\n",
            "W2\n",
            "[[ 0.25052603]\n",
            " [-0.16303889]]\n",
            "W2\n",
            "[[ 0.25058095]\n",
            " [-0.1628929 ]]\n",
            "W2\n",
            "[[ 0.25063608]\n",
            " [-0.16274568]]\n",
            "W2\n",
            "[[ 0.25069133]\n",
            " [-0.16259746]]\n",
            "W2\n",
            "[[ 0.25074665]\n",
            " [-0.16244843]]\n",
            "W2\n",
            "[[ 0.25080199]\n",
            " [-0.16229876]]\n",
            "W2\n",
            "[[ 0.25085729]\n",
            " [-0.1621486 ]]\n",
            "W2\n",
            "[[ 0.25091253]\n",
            " [-0.16199809]]\n",
            "W2\n",
            "[[ 0.25096766]\n",
            " [-0.16184735]]\n",
            "W2\n",
            "[[ 0.25102264]\n",
            " [-0.16169648]]\n",
            "W2\n",
            "[[ 0.25107746]\n",
            " [-0.16154559]]\n",
            "W2\n",
            "[[ 0.25113209]\n",
            " [-0.16139475]]\n",
            "W2\n",
            "[[ 0.2511865 ]\n",
            " [-0.16124403]]\n",
            "W2\n",
            "[[ 0.25124068]\n",
            " [-0.1610935 ]]\n",
            "W2\n",
            "[[ 0.25129461]\n",
            " [-0.16094323]]\n",
            "W2\n",
            "[[ 0.25134826]\n",
            " [-0.16079325]]\n",
            "W2\n",
            "[[ 0.25140165]\n",
            " [-0.16064362]]\n",
            "W2\n",
            "[[ 0.25145473]\n",
            " [-0.16049437]]\n",
            "W2\n",
            "[[ 0.25150752]\n",
            " [-0.16034554]]\n",
            "W2\n",
            "[[ 0.25156   ]\n",
            " [-0.16019715]]\n",
            "W2\n",
            "[[ 0.25161217]\n",
            " [-0.16004925]]\n",
            "W2\n",
            "[[ 0.25166401]\n",
            " [-0.15990184]]\n",
            "W2\n",
            "[[ 0.25171552]\n",
            " [-0.15975495]]\n",
            "W2\n",
            "[[ 0.2517667 ]\n",
            " [-0.15960859]]\n",
            "W2\n",
            "[[ 0.25181754]\n",
            " [-0.15946279]]\n",
            "W2\n",
            "[[ 0.25186805]\n",
            " [-0.15931756]]\n",
            "W2\n",
            "[[ 0.25191821]\n",
            " [-0.1591729 ]]\n",
            "W2\n",
            "[[ 0.25196802]\n",
            " [-0.15902883]]\n",
            "W2\n",
            "[[ 0.25201749]\n",
            " [-0.15888535]]\n",
            "W2\n",
            "[[ 0.25206661]\n",
            " [-0.15874248]]\n",
            "W2\n",
            "[[ 0.25211538]\n",
            " [-0.15860021]]\n",
            "W2\n",
            "[[ 0.2521638 ]\n",
            " [-0.15845856]]\n",
            "W2\n",
            "[[ 0.25221188]\n",
            " [-0.15831753]]\n",
            "W2\n",
            "[[ 0.2522596 ]\n",
            " [-0.15817711]]\n",
            "W2\n",
            "[[ 0.25230697]\n",
            " [-0.15803732]]\n",
            "W2\n",
            "[[ 0.25235399]\n",
            " [-0.15789815]]\n",
            "W2\n",
            "[[ 0.25240066]\n",
            " [-0.15775961]]\n",
            "W2\n",
            "[[ 0.25244699]\n",
            " [-0.1576217 ]]\n",
            "W2\n",
            "[[ 0.25249296]\n",
            " [-0.15748441]]\n",
            "W2\n",
            "[[ 0.25253859]\n",
            " [-0.15734775]]\n",
            "W2\n",
            "[[ 0.25258388]\n",
            " [-0.15721171]]\n",
            "W2\n",
            "[[ 0.25262881]\n",
            " [-0.1570763 ]]\n",
            "W2\n",
            "[[ 0.25267341]\n",
            " [-0.15694152]]\n",
            "W2\n",
            "[[ 0.25271766]\n",
            " [-0.15680736]]\n",
            "W2\n",
            "[[ 0.25276156]\n",
            " [-0.15667382]]\n",
            "W2\n",
            "[[ 0.25280513]\n",
            " [-0.15654091]]\n",
            "W2\n",
            "[[ 0.25284836]\n",
            " [-0.15640861]]\n",
            "W2\n",
            "[[ 0.25289125]\n",
            " [-0.15627693]]\n",
            "W2\n",
            "[[ 0.25293381]\n",
            " [-0.15614587]]\n",
            "W2\n",
            "[[ 0.25297603]\n",
            " [-0.15601542]]\n",
            "W2\n",
            "[[ 0.25301792]\n",
            " [-0.15588557]]\n",
            "W2\n",
            "[[ 0.25305948]\n",
            " [-0.15575634]]\n",
            "W2\n",
            "[[ 0.2531007 ]\n",
            " [-0.15562772]]\n",
            "W2\n",
            "[[ 0.2531416 ]\n",
            " [-0.15549969]]\n",
            "W2\n",
            "[[ 0.25318217]\n",
            " [-0.15537227]]\n",
            "W2\n",
            "[[ 0.25322242]\n",
            " [-0.15524545]]\n",
            "W2\n",
            "[[ 0.25326234]\n",
            " [-0.15511922]]\n",
            "W2\n",
            "[[ 0.25330194]\n",
            " [-0.15499359]]\n",
            "W2\n",
            "[[ 0.25334122]\n",
            " [-0.15486855]]\n",
            "W2\n",
            "[[ 0.25338018]\n",
            " [-0.15474409]]\n",
            "W2\n",
            "[[ 0.25341883]\n",
            " [-0.15462022]]\n",
            "W2\n",
            "[[ 0.25345715]\n",
            " [-0.15449694]]\n",
            "W2\n",
            "[[ 0.25349517]\n",
            " [-0.15437423]]\n",
            "W2\n",
            "[[ 0.25353287]\n",
            " [-0.1542521 ]]\n",
            "W2\n",
            "[[ 0.25357026]\n",
            " [-0.15413055]]\n",
            "W2\n",
            "[[ 0.25360734]\n",
            " [-0.15400957]]\n",
            "W2\n",
            "[[ 0.25364412]\n",
            " [-0.15388915]]\n",
            "W2\n",
            "[[ 0.25368058]\n",
            " [-0.15376931]]\n",
            "W2\n",
            "[[ 0.25371675]\n",
            " [-0.15365002]]\n",
            "W2\n",
            "[[ 0.25375261]\n",
            " [-0.1535313 ]]\n",
            "W2\n",
            "[[ 0.25378817]\n",
            " [-0.15341314]]\n",
            "W2\n",
            "[[ 0.25382343]\n",
            " [-0.15329553]]\n",
            "W2\n",
            "[[ 0.25385839]\n",
            " [-0.15317847]]\n",
            "W2\n",
            "[[ 0.25389306]\n",
            " [-0.15306196]]\n",
            "W2\n",
            "[[ 0.25392743]\n",
            " [-0.152946  ]]\n",
            "W2\n",
            "[[ 0.25396151]\n",
            " [-0.15283059]]\n",
            "W2\n",
            "[[ 0.2539953 ]\n",
            " [-0.15271572]]\n",
            "W2\n",
            "[[ 0.25402879]\n",
            " [-0.15260138]]\n",
            "W2\n",
            "[[ 0.254062  ]\n",
            " [-0.15248758]]\n",
            "W2\n",
            "[[ 0.25409492]\n",
            " [-0.15237432]]\n",
            "W2\n",
            "[[ 0.25412756]\n",
            " [-0.15226159]]\n",
            "W2\n",
            "[[ 0.25415991]\n",
            " [-0.15214938]]\n",
            "W2\n",
            "[[ 0.25419198]\n",
            " [-0.1520377 ]]\n",
            "W2\n",
            "[[ 0.25422378]\n",
            " [-0.15192655]]\n",
            "W2\n",
            "[[ 0.25425529]\n",
            " [-0.15181591]]\n",
            "W2\n",
            "[[ 0.25428652]\n",
            " [-0.1517058 ]]\n",
            "W2\n",
            "[[ 0.25431748]\n",
            " [-0.1515962 ]]\n",
            "W2\n",
            "[[ 0.25434816]\n",
            " [-0.15148711]]\n",
            "W2\n",
            "[[ 0.25437857]\n",
            " [-0.15137853]]\n",
            "W2\n",
            "[[ 0.25440871]\n",
            " [-0.15127046]]\n",
            "W2\n",
            "[[ 0.25443858]\n",
            " [-0.15116289]]\n",
            "W2\n",
            "[[ 0.25446818]\n",
            " [-0.15105583]]\n",
            "W2\n",
            "[[ 0.25449751]\n",
            " [-0.15094927]]\n",
            "W2\n",
            "[[ 0.25452658]\n",
            " [-0.1508432 ]]\n",
            "W2\n",
            "[[ 0.25455538]\n",
            " [-0.15073763]]\n",
            "W2\n",
            "[[ 0.25458392]\n",
            " [-0.15063255]]\n",
            "W2\n",
            "[[ 0.2546122 ]\n",
            " [-0.15052796]]\n",
            "W2\n",
            "[[ 0.25464022]\n",
            " [-0.15042386]]\n",
            "W2\n",
            "[[ 0.25466776]\n",
            " [-0.15032026]]\n",
            "W2\n",
            "[[ 0.25467127]\n",
            " [-0.15029567]]\n",
            "W2\n",
            "[[ 0.25467738]\n",
            " [-0.15026252]]\n",
            "W2\n",
            "[[ 0.25468575]\n",
            " [-0.1502218 ]]\n",
            "W2\n",
            "[[ 0.25469611]\n",
            " [-0.1501744 ]]\n",
            "W2\n",
            "[[ 0.25470822]\n",
            " [-0.15012113]]\n",
            "W2\n",
            "[[ 0.25472185]\n",
            " [-0.15006268]]\n",
            "W2\n",
            "[[ 0.2547368 ]\n",
            " [-0.14999969]]\n",
            "W2\n",
            "[[ 0.2547529]\n",
            " [-0.1499327]]\n",
            "W2\n",
            "[[ 0.25477   ]\n",
            " [-0.14986221]]\n",
            "W2\n",
            "[[ 0.25478796]\n",
            " [-0.14978865]]\n",
            "W2\n",
            "[[ 0.25480665]\n",
            " [-0.14971243]]\n",
            "W2\n",
            "[[ 0.25482597]\n",
            " [-0.14963389]]\n",
            "W2\n",
            "[[ 0.25484583]\n",
            " [-0.14955332]]\n",
            "W2\n",
            "[[ 0.25486613]\n",
            " [-0.14947102]]\n",
            "W2\n",
            "[[ 0.25488681]\n",
            " [-0.14938721]]\n",
            "W2\n",
            "[[ 0.25490779]\n",
            " [-0.14930212]]\n",
            "W2\n",
            "[[ 0.25492901]\n",
            " [-0.14921594]]\n",
            "W2\n",
            "[[ 0.25495043]\n",
            " [-0.14912884]]\n",
            "W2\n",
            "[[ 0.25497199]\n",
            " [-0.14904096]]\n",
            "W2\n",
            "[[ 0.25499366]\n",
            " [-0.14895244]]\n",
            "W2\n",
            "[[ 0.2550154 ]\n",
            " [-0.14886341]]\n",
            "W2\n",
            "[[ 0.25503717]\n",
            " [-0.14877396]]\n",
            "W2\n",
            "[[ 0.25505895]\n",
            " [-0.14868419]]\n",
            "W2\n",
            "[[ 0.25508071]\n",
            " [-0.14859418]]\n",
            "W2\n",
            "[[ 0.25510243]\n",
            " [-0.14850401]]\n",
            "W2\n",
            "[[ 0.25512409]\n",
            " [-0.14841373]]\n",
            "W2\n",
            "[[ 0.25514567]\n",
            " [-0.14832342]]\n",
            "W2\n",
            "[[ 0.25516716]\n",
            " [-0.14823311]]\n",
            "W2\n",
            "[[ 0.25518854]\n",
            " [-0.14814286]]\n",
            "W2\n",
            "[[ 0.25520981]\n",
            " [-0.14805271]]\n",
            "W2\n",
            "[[ 0.25523094]\n",
            " [-0.14796268]]\n",
            "W2\n",
            "[[ 0.25525194]\n",
            " [-0.14787281]]\n",
            "W2\n",
            "[[ 0.25527278]\n",
            " [-0.14778313]]\n",
            "W2\n",
            "[[ 0.25529348]\n",
            " [-0.14769366]]\n",
            "W2\n",
            "[[ 0.25531402]\n",
            " [-0.14760443]]\n",
            "W2\n",
            "[[ 0.25533439]\n",
            " [-0.14751545]]\n",
            "W2\n",
            "[[ 0.25535459]\n",
            " [-0.14742673]]\n",
            "W2\n",
            "[[ 0.25537462]\n",
            " [-0.1473383 ]]\n",
            "W2\n",
            "[[ 0.25539448]\n",
            " [-0.14725016]]\n",
            "W2\n",
            "[[ 0.25541415]\n",
            " [-0.14716233]]\n",
            "W2\n",
            "[[ 0.25543365]\n",
            " [-0.14707481]]\n",
            "W2\n",
            "[[ 0.25545296]\n",
            " [-0.14698762]]\n",
            "W2\n",
            "[[ 0.25547208]\n",
            " [-0.14690075]]\n",
            "W2\n",
            "[[ 0.25549102]\n",
            " [-0.14681422]]\n",
            "W2\n",
            "[[ 0.25550977]\n",
            " [-0.14672804]]\n",
            "W2\n",
            "[[ 0.25552833]\n",
            " [-0.1466422 ]]\n",
            "W2\n",
            "[[ 0.25554671]\n",
            " [-0.14655671]]\n",
            "W2\n",
            "[[ 0.25556489]\n",
            " [-0.14647157]]\n",
            "W2\n",
            "[[ 0.25558288]\n",
            " [-0.14638679]]\n",
            "W2\n",
            "[[ 0.25560069]\n",
            " [-0.14630237]]\n",
            "W2\n",
            "[[ 0.2556183]\n",
            " [-0.1462183]]\n",
            "W2\n",
            "[[ 0.25563573]\n",
            " [-0.1461346 ]]\n",
            "W2\n",
            "[[ 0.25565297]\n",
            " [-0.14605125]]\n",
            "W2\n",
            "[[ 0.25567001]\n",
            " [-0.14596827]]\n",
            "W2\n",
            "[[ 0.25568687]\n",
            " [-0.14588565]]\n",
            "W2\n",
            "[[ 0.25570354]\n",
            " [-0.14580339]]\n",
            "W2\n",
            "[[ 0.25572003]\n",
            " [-0.1457215 ]]\n",
            "W2\n",
            "[[ 0.25573632]\n",
            " [-0.14563996]]\n",
            "W2\n",
            "[[ 0.25575243]\n",
            " [-0.14555879]]\n",
            "W2\n",
            "[[ 0.25576836]\n",
            " [-0.14547797]]\n",
            "W2\n",
            "[[ 0.2557841 ]\n",
            " [-0.14539752]]\n",
            "W2\n",
            "[[ 0.25579966]\n",
            " [-0.14531743]]\n",
            "W2\n",
            "[[ 0.25581503]\n",
            " [-0.14523769]]\n",
            "W2\n",
            "[[ 0.25583023]\n",
            " [-0.14515831]]\n",
            "W2\n",
            "[[ 0.25584524]\n",
            " [-0.14507929]]\n",
            "W2\n",
            "[[ 0.25586007]\n",
            " [-0.14500062]]\n",
            "W2\n",
            "[[ 0.25587472]\n",
            " [-0.1449223 ]]\n",
            "W2\n",
            "[[ 0.25588919]\n",
            " [-0.14484434]]\n",
            "W2\n",
            "[[ 0.25590349]\n",
            " [-0.14476672]]\n",
            "W2\n",
            "[[ 0.25591761]\n",
            " [-0.14468946]]\n",
            "W2\n",
            "[[ 0.25593155]\n",
            " [-0.14461254]]\n",
            "W2\n",
            "[[ 0.25594532]\n",
            " [-0.14453597]]\n",
            "W2\n",
            "[[ 0.25595891]\n",
            " [-0.14445975]]\n",
            "W2\n",
            "[[ 0.25597234]\n",
            " [-0.14438386]]\n",
            "W2\n",
            "[[ 0.25598559]\n",
            " [-0.14430832]]\n",
            "W2\n",
            "[[ 0.25599867]\n",
            " [-0.14423312]]\n",
            "W2\n",
            "[[ 0.25601158]\n",
            " [-0.14415826]]\n",
            "W2\n",
            "[[ 0.25602432]\n",
            " [-0.14408374]]\n",
            "W2\n",
            "[[ 0.25603689]\n",
            " [-0.14400955]]\n",
            "W2\n",
            "[[ 0.25604929]\n",
            " [-0.14393569]]\n",
            "W2\n",
            "[[ 0.25606153]\n",
            " [-0.14386217]]\n",
            "W2\n",
            "[[ 0.25607361]\n",
            " [-0.14378898]]\n",
            "W2\n",
            "[[ 0.25608552]\n",
            " [-0.14371612]]\n",
            "W2\n",
            "[[ 0.25609726]\n",
            " [-0.14364359]]\n",
            "W2\n",
            "[[ 0.25610885]\n",
            " [-0.14357138]]\n",
            "W2\n",
            "[[ 0.25612027]\n",
            " [-0.1434995 ]]\n",
            "W2\n",
            "[[ 0.25613154]\n",
            " [-0.14342794]]\n",
            "W2\n",
            "[[ 0.25614264]\n",
            " [-0.1433567 ]]\n",
            "W2\n",
            "[[ 0.25615359]\n",
            " [-0.14328578]]\n",
            "W2\n",
            "[[ 0.25616438]\n",
            " [-0.14321518]]\n",
            "W2\n",
            "[[ 0.25617501]\n",
            " [-0.1431449 ]]\n",
            "W2\n",
            "[[ 0.25618548]\n",
            " [-0.14307493]]\n",
            "W2\n",
            "[[ 0.25619581]\n",
            " [-0.14300528]]\n",
            "W2\n",
            "[[ 0.25620597]\n",
            " [-0.14293593]]\n",
            "W2\n",
            "[[ 0.25621599]\n",
            " [-0.1428669 ]]\n",
            "W2\n",
            "[[ 0.25622585]\n",
            " [-0.14279818]]\n",
            "W2\n",
            "[[ 0.25623557]\n",
            " [-0.14272977]]\n",
            "W2\n",
            "[[ 0.25624513]\n",
            " [-0.14266166]]\n",
            "W2\n",
            "[[ 0.25625454]\n",
            " [-0.14259385]]\n",
            "W2\n",
            "[[ 0.25626381]\n",
            " [-0.14252635]]\n",
            "W2\n",
            "[[ 0.25627293]\n",
            " [-0.14245915]]\n",
            "W2\n",
            "[[ 0.2562819 ]\n",
            " [-0.14239225]]\n",
            "W2\n",
            "[[ 0.25629073]\n",
            " [-0.14232565]]\n",
            "W2\n",
            "[[ 0.25629941]\n",
            " [-0.14225935]]\n",
            "W2\n",
            "[[ 0.25630795]\n",
            " [-0.14219334]]\n",
            "W2\n",
            "[[ 0.25631634]\n",
            " [-0.14212763]]\n",
            "W2\n",
            "[[ 0.2563246 ]\n",
            " [-0.14206221]]\n",
            "W2\n",
            "[[ 0.25633271]\n",
            " [-0.14199708]]\n",
            "W2\n",
            "[[ 0.25634068]\n",
            " [-0.14193224]]\n",
            "W2\n",
            "[[ 0.25634852]\n",
            " [-0.14186768]]\n",
            "W2\n",
            "[[ 0.25635621]\n",
            " [-0.14180342]]\n",
            "W2\n",
            "[[ 0.25636377]\n",
            " [-0.14173944]]\n",
            "W2\n",
            "[[ 0.25637119]\n",
            " [-0.14167574]]\n",
            "W2\n",
            "[[ 0.25637847]\n",
            " [-0.14161233]]\n",
            "W2\n",
            "[[ 0.25638562]\n",
            " [-0.1415492 ]]\n",
            "W2\n",
            "[[ 0.25639264]\n",
            " [-0.14148635]]\n",
            "W2\n",
            "[[ 0.25639952]\n",
            " [-0.14142377]]\n",
            "W2\n",
            "[[ 0.25640627]\n",
            " [-0.14136148]]\n",
            "W2\n",
            "[[ 0.25641289]\n",
            " [-0.14129946]]\n",
            "W2\n",
            "[[ 0.25641937]\n",
            " [-0.14123771]]\n",
            "W2\n",
            "[[ 0.25642573]\n",
            " [-0.14117624]]\n",
            "W2\n",
            "[[ 0.25643196]\n",
            " [-0.14111503]]\n",
            "W2\n",
            "[[ 0.25643806]\n",
            " [-0.1410541 ]]\n",
            "W2\n",
            "[[ 0.25644403]\n",
            " [-0.14099344]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "2cjqu25q91LA",
        "outputId": "5f606911-c90e-4889-968b-ce6083976b75"
      },
      "source": [
        "\"\"\"\n",
        "i = 0\n",
        "y = np.zeros(100)\n",
        "\n",
        "\n",
        "N = 4#データ数(ミニバッチ)\n",
        "learning_rate = 0.2#学習率\n",
        "pram_b1 = 0.9\n",
        "pram_b2 = 0.999\n",
        "epsiron = 0.00000001\n",
        "alfa = 0.0001\n",
        "m = 0\n",
        "v = 0\n",
        "for i in range(100):\n",
        "  \n",
        "  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\n",
        "  target =  np.array([[0],[1],[1],[0]]) #教師\n",
        "  \n",
        "\n",
        "  A1 = np.dot(x,W1)+B1\n",
        "  Z1 = relu(A1)#一層目活性化関数かける\n",
        "  #print(\"Z1\")\n",
        "  #print(Z1)\n",
        "  A2 = np.dot(Z1,W2) + B2\n",
        "  Z2 = sigmoid(A2)\n",
        "  #print(\"Z2\")\n",
        "  #print(Z2)\n",
        "  #print(\"target\")\n",
        "  #print(target)\n",
        "  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\n",
        "  \n",
        "  #print(y)\n",
        "\n",
        "  ###出力層の逆伝搬\n",
        "  ##重み\n",
        "  delta = Z2 - target#誤差\n",
        "  #print(Z2)\n",
        "  #print(\"delta\")\n",
        "  #print(delta)\n",
        "  Z1_t = np.transpose(Z1)\n",
        "  #print(Z1_t)\n",
        "  sum_delta = np.dot(Z1_t,delta)\n",
        "  #print(\"sum_delta\")\n",
        "  #print(sum_delta)\n",
        "  \n",
        "  #print(\"delta_out\")\n",
        "  #delta_out　なんか違う\n",
        "  delta_out =(1/N)*sum_delta\n",
        "  #print(\"delta_out\")\n",
        "  #print(delta_out)\n",
        "  \n",
        "  print(\"W2\")\n",
        "  print(W2)\n",
        " \n",
        "  m = pram_b1*m + (1-pram_b2)*(delta_out + alfa*W2)\n",
        "  v = pram_b2*v + (1-pram_b2)*(delta_out + alfa*W2)**2\n",
        "  m = m/(1-pram_b1**(i+1))\n",
        "  v = v/(1-pram_b2**(i+1))\n",
        "  W2 = W2 - learning_rate*m/(np.sqrt(v)+epsiron)\n",
        "  print(\"W2\")\n",
        "  print(W2)\n",
        "\n",
        "\n",
        "  ##バイアス\n",
        "  a = np.array([1,1,1,1])\n",
        "  sum_delta_bias = np.dot(a,delta)\n",
        "  delta_out_bias = 1/N*sum_delta_bias\n",
        "  #print(delta_out_bias)\n",
        "  #print(B2)\n",
        "  B2 = B2 - learning_rate*delta_out_bias\n",
        "  #print(\"B2\")\n",
        "  #print(B2)\n",
        "\n",
        "  ###隠れ層の逆伝搬\n",
        "  ##重み\n",
        "  differential_y = relu_diff(Z1)#活性化関数の微分\n",
        "  print(differential_y)\n",
        "  hid_delta = hidden_delta(delta,W2,differential_y)\n",
        "  #print(hid_delta)\n",
        "  x_t = np.transpose(x)\n",
        "  delta_hidden = 1/N*np.dot(x_t,hid_delta)\n",
        "  W1 = W1 - learning_rate*delta_hidden\n",
        "  #print(\"W1\")\n",
        "  #print(W1)\n",
        "\n",
        "  ##バイアス\n",
        "  a2 = np.array([1,1,1,1])\n",
        "  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\n",
        "  #print(B1)\n",
        "  B1 = B1 - learning_rate*delta_hidden_bias\n",
        "  #print(\"B1\")\n",
        "  #print(B1)\n",
        "\"\"\""
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ni = 0\\ny = np.zeros(100)\\n\\n\\nN = 4#データ数(ミニバッチ)\\nlearning_rate = 0.2#学習率\\npram_b1 = 0.9\\npram_b2 = 0.999\\nepsiron = 0.00000001\\nalfa = 0.0001\\nm = 0\\nv = 0\\nfor i in range(100):\\n  \\n  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\\n  target =  np.array([[0],[1],[1],[0]]) #教師\\n  \\n\\n  A1 = np.dot(x,W1)+B1\\n  Z1 = relu(A1)#一層目活性化関数かける\\n  #print(\"Z1\")\\n  #print(Z1)\\n  A2 = np.dot(Z1,W2) + B2\\n  Z2 = sigmoid(A2)\\n  #print(\"Z2\")\\n  #print(Z2)\\n  #print(\"target\")\\n  #print(target)\\n  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\\n  \\n  #print(y)\\n\\n  ###出力層の逆伝搬\\n  ##重み\\n  delta = Z2 - target#誤差\\n  #print(Z2)\\n  #print(\"delta\")\\n  #print(delta)\\n  Z1_t = np.transpose(Z1)\\n  #print(Z1_t)\\n  sum_delta = np.dot(Z1_t,delta)\\n  #print(\"sum_delta\")\\n  #print(sum_delta)\\n  \\n  #print(\"delta_out\")\\n  #delta_out\\u3000なんか違う\\n  delta_out =(1/N)*sum_delta\\n  #print(\"delta_out\")\\n  #print(delta_out)\\n  \\n  print(\"W2\")\\n  print(W2)\\n \\n  m = pram_b1*m + (1-pram_b2)*(delta_out + alfa*W2)\\n  v = pram_b2*v + (1-pram_b2)*(delta_out + alfa*W2)**2\\n  m = m/(1-pram_b1**(i+1))\\n  v = v/(1-pram_b2**(i+1))\\n  W2 = W2 - learning_rate*m/(np.sqrt(v)+epsiron)\\n  print(\"W2\")\\n  print(W2)\\n\\n\\n  ##バイアス\\n  a = np.array([1,1,1,1])\\n  sum_delta_bias = np.dot(a,delta)\\n  delta_out_bias = 1/N*sum_delta_bias\\n  #print(delta_out_bias)\\n  #print(B2)\\n  B2 = B2 - learning_rate*delta_out_bias\\n  #print(\"B2\")\\n  #print(B2)\\n\\n  ###隠れ層の逆伝搬\\n  ##重み\\n  differential_y = relu_diff(Z1)#活性化関数の微分\\n  print(differential_y)\\n  hid_delta = hidden_delta(delta,W2,differential_y)\\n  #print(hid_delta)\\n  x_t = np.transpose(x)\\n  delta_hidden = 1/N*np.dot(x_t,hid_delta)\\n  W1 = W1 - learning_rate*delta_hidden\\n  #print(\"W1\")\\n  #print(W1)\\n\\n  ##バイアス\\n  a2 = np.array([1,1,1,1])\\n  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\\n  #print(B1)\\n  B1 = B1 - learning_rate*delta_hidden_bias\\n  #print(\"B1\")\\n  #print(B1)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4TalPJTI39Oy",
        "outputId": "d7fe7e8c-17b2-4d0c-940e-2dceaf1c8294"
      },
      "source": [
        "p = np.arange(300)\n",
        "plt.scatter(p, y, c='b', label='loss_data')\n",
        "#plt.legend()\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BZlWMYObD1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b415c98a-b23b-4dda-f652-651fca4083c0"
      },
      "source": [
        "A1 = np.dot(x,W1) +B1\n",
        "Z1 = relu(A1)#一層目活性化関数かける\n",
        "\n",
        "\n",
        "A2 = np.dot(Z1,W2)+B2\n",
        "Z22 = sigmoid(A2)\n",
        "\n",
        "delta = Z2 - target#誤差\n",
        "#print(delta)\n",
        "print(Z22)\n",
        "print(Z2)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49985275]\n",
            " [0.50546139]\n",
            " [0.49512667]\n",
            " [0.50073536]]\n",
            "[[0.49986138]\n",
            " [0.50547139]\n",
            " [0.49511985]\n",
            " [0.50072992]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUgxJbD0o_zy"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxGiQAg-o_ob"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4poqP4Loo_bw"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui7jl1ERpD2h"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrPIQcknpGdf"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    }
  ]
}