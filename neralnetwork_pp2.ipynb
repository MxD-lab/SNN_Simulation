{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neralnetwork_pp2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8oYhJDisr02XKsgYJgwTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MxD-lab/SNN_Simulation/blob/neralnetwork/neralnetwork_pp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXqeJqPsidF1"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWy2IoGhwJJ1"
      },
      "source": [
        "\"\"\"\n",
        "活性化関数たち\n",
        "\"\"\"\n",
        "#シグモイド関数\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#ソフトマックス関数\n",
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a-c)#オーバーフロー対策\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a/sum_exp_a\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUU4LueszmfY"
      },
      "source": [
        "\"\"\"\n",
        "損失関数たち\n",
        "\"\"\"\n",
        "#2乗和誤差\n",
        "def mean_squared_error(y,t):\n",
        "  return 0.5*np.sum((y-t)**2)\n",
        "\n",
        "#交差エントロピー誤差\n",
        "def cross_entropy_error(y,t):\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t*np.log(y+delta))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYKiGKB1mMce"
      },
      "source": [
        "\"\"\"\n",
        "3層ニューラルネットワーク\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "X = np.array([1.0,0.5])#入力\n",
        "W1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])#1層目の重み\n",
        "B1 = np.array([0.1,0.2,0.3])#1層目の閾値\n",
        "\n",
        "A1 = np.dot(X,W1)+B1\n",
        "Z1 = sigmoid(A1)#1層目活性化関数をかける\n",
        "\n",
        "W2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])#1層目から2層目への重み\n",
        "B2 = np.array([0.1,0.2])#1層目から2層目の閾値\n",
        "\n",
        "A2 = np.dot(Z1,W2)+B2\n",
        "Z2 = sigmoid(A2)#2層目活性化関数をかける\n",
        "\n",
        "def identity_function(x):#出力層の活性化関数\n",
        "  return x\n",
        "  \n",
        "W3 = np.array([[0.1,0.3],[0.2,0.4]])#2層目から3層目への重み\n",
        "B3 = np.array([0.1,0.2])#2層目から3層目の閾値\n",
        "\n",
        "A3 = np.dot(Z2,W3)+B3\n",
        "Y = identity_function(A3)#出力層活性化関数をかける\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60aQCkjam0Fa",
        "outputId": "e5c322c4-bb4b-43dd-b612-deb22b1ea5eb"
      },
      "source": [
        "#↑まとめ\n",
        "def init_network():\n",
        "  network = {}\n",
        "  network[\"W1\"] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])#1層目の重み\n",
        "  network[\"b1\"] = np.array([0.1,0.2,0.3])#1層目の閾値\n",
        "  network[\"W2\"] = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])#1層目から2層目への重み\n",
        "  network[\"b2\"] = np.array([0.1,0.2])#1層目から2層目の閾値\n",
        "  network[\"W3\"] = np.array([[0.1,0.3],[0.2,0.4]])#2層目から3層目への重み\n",
        "  network[\"b3\"] = np.array([0.1,0.2])#2層目から3層目の閾値\n",
        "\n",
        "  return network\n",
        "\n",
        "def forward(network,x):\n",
        "  W1,W2,W3 = network[\"W1\"],network[\"W2\"],network[\"W3\"]\n",
        "  b1,b2,b3 = network[\"b1\"],network[\"b2\"],network[\"b3\"]\n",
        "\n",
        "  a1 = np.dot(x,W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "  a2 = np.dot(z1,W2) + b2\n",
        "  z2 = sigmoid(a2)\n",
        "  a3 = np.dot(z2,W3) + b3\n",
        "  y  = identity_function(a3)\n",
        "\n",
        "  return y\n",
        "\n",
        "network = init_network()\n",
        "x = np.array([1.0,0.5])\n",
        "y = forward(network,x)\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31682708 0.69627909]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKzC7nosu51Q"
      },
      "source": [
        "\"\"\"\n",
        "勾配\n",
        "\"\"\"\n",
        "def numerical_gradient(f,x):\n",
        "  h = 1e-4 #0.0001\n",
        "  grad = np.zeros_like(x) #xと同じ形状の配列を作成\n",
        "\n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]\n",
        "\n",
        "    #f(x+h)の計算\n",
        "    x[idx]= tmp_val + h #f(x+h)の計算\n",
        "    fxh1 = f(x)\n",
        "\n",
        "    #f(x-h)の計算\n",
        "    x[idx]= tmp_val - h #f(x-h)の計算\n",
        "    fxh2 = f(x)\n",
        "\n",
        "    grad[idx] = (fxh1 - fxh2)/(2*h)\n",
        "    x[idx] = tmp_val #値を元に戻す\n",
        "\n",
        "  return grad\n",
        "\n",
        "  \"\"\"\n",
        "勾配化法\n",
        "\n",
        "init_x:初期値\n",
        "lr:learning rate(学習率)\n",
        "step_num:勾配法による繰り返し回数\n",
        "\n",
        "勾配をnumerical_gradientで求めて、\n",
        "その勾配に学習率を掛けた値で更新する処理を\n",
        "step_numで指定された回数繰り返す\n",
        "\"\"\"\n",
        "\n",
        "def gradient_descent(f,init_x,lr= 0.01,step_num = 100):\n",
        "  x = init_x\n",
        "\n",
        "  for i in range(step_num):\n",
        "    grad = numerical_gradient(f,x)\n",
        "\n",
        "    x -= lr *grad\n",
        "  \n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BAiTiAGAahb"
      },
      "source": [
        "\"\"\"\n",
        "2層ニューラルネットワークの学習\n",
        "\"\"\"\n",
        "class TwoLayerNet:\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,output_size,weight_init_std = 0.01):\n",
        "    \n",
        "    #重みの初期化\n",
        "    self.params = {}\n",
        "    self.params[\"W1\"] = weight_init_std*\\\n",
        "                        np.random.randn(input_size,hidden_size)\n",
        "    \n",
        "    self.params[\"b1\"] = np.zeros(hidden_size)\n",
        "\n",
        "    self.params[\"W2\"] = weight_init_std*\\\n",
        "                        np.random.randn(hidden_size,output_size)\n",
        "    \n",
        "    self.params[\"b2\"] = np.zeros(output_size)\n",
        "\n",
        "  #推論を行う\n",
        "  def predict(self,x):\n",
        "    W1,W2 = self.params[\"W1\"],self.params[\"W2\"]\n",
        "    b1,b2 = self.params[\"b1\"],self.params[\"b2\"]\n",
        "\n",
        "    a1 = np.dot(x,W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1,W2) + b2\n",
        "    y = softmax(a2)\n",
        "\n",
        "    return y\n",
        "\n",
        "  #ｘ：入力データ、t：教師データ\n",
        "  def loss(self,x,t):\n",
        "    y = self.predict(x)\n",
        "\n",
        "    return cross_entropy_error(y,t)\n",
        "\n",
        "  #認知精度を求める\n",
        "  def accuracy(self,x,t):\n",
        "    y = predict(x)\n",
        "    #最大値を返す axis:次元\n",
        "    accuracy = np.sum(y==t)/float(x.shape[0])\n",
        "    return accuracy\n",
        "\n",
        "  def numerical_gradient(self,x,t):\n",
        "    loss_W = lambda W:self.loss(x,t)\n",
        "\n",
        "    grads = {}#勾配を保持するディクショナリ関数\n",
        "    grads[\"W1\"] = numerical_gradient(loss_W,self.params[\"W1\"])\n",
        "    grads[\"b1\"] = numerical_gradient(loss_W,self.params[\"b1\"])\n",
        "    grads[\"W2\"] = numerical_gradient(loss_W,self.params[\"W2\"])\n",
        "    grads[\"b2\"] = numerical_gradient(loss_W,self.params[\"b2\"])\n",
        "\n",
        "    return grads\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "pX7e4xaDytND",
        "outputId": "e151198c-1e78-449a-aca5-115f3cadab4b"
      },
      "source": [
        "\n",
        "net = TwoLayerNet(input_size=784,hidden_size=100,output_size=10)\n",
        "x= np.random.rand(100,784)#ダミー入力データ\n",
        "t = np.random.rand(100,10)#ダミーテストデータ\n",
        "y = net.predict(x)\n",
        "\n",
        "grads = net.numerical_gradient(x,t)#勾配を計算"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6e0aba118aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#勾配を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-237394689d04>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m#勾配を保持するディクショナリ関数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-873589f256fa>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtmp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#f(x+h)の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 784 is out of bounds for axis 0 with size 784"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmkYNojWzrvc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}