{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neralnetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MxD-lab/SNN_Simulation/blob/neralnetwork/neralnetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDoqQNyWTZA4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmHemqNMVycT"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import numpy \n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVfiDGT0TSiz"
      },
      "source": [
        "#シグモイド関数（出力層）\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#ReLU関数（隠れ層）\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtffoYMfTPc1"
      },
      "source": [
        "#交差エントロピー誤差\n",
        "\n",
        "def cross_entropy_error(y,t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1,t.size)\n",
        "    y = y.reshape(1,y.size)\n",
        "  \n",
        "  batch_size = y.shape[0]#yの行数\n",
        "  return np.sum(-t*np.log(y)-(1-t)*np.log(1-y))/batch_size\n",
        "\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2vL9vh16z4r"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM8pe9UDRs3V"
      },
      "source": [
        "\"\"\"\n",
        "重み、バイアス、初期設定\n",
        "W1：隠れ層の重み\n",
        "B1:隠れ層のバイアス\n",
        "W2:出力層の重み\n",
        "B2:隠れ層のバイアス\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "W1 = np.random.rand(2,12)\n",
        "B1 = np.random.rand(12)\n",
        "W2 = np.random.rand(12,1)\n",
        "B2 = np.random.rand(1)\n",
        "#print(W1)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IObJ4TdZvMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2ed29af4-59c9-414c-de9c-9ff9acc626ba"
      },
      "source": [
        "#活性化関数の微分(relu)u:隠れ層の活性\n",
        "\n",
        "def relu_diff(u):\n",
        "  d = np.zeros_like(u) #xと同じ形状の配列を作成\n",
        "  for i in range(len(u)):\n",
        "    for j in range(len(u[0])):\n",
        "      if u[i][j]>0:\n",
        "        d[i][j] = 1\n",
        "      else: \n",
        "        d[i][j] = 0\n",
        "\n",
        "  return d\n",
        "\n",
        "\"\"\"\n",
        "def relu_diff(u):\n",
        "  d = np.where( x > 0, 1, 0)\n",
        "  return y\n",
        "\"\"\""
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef relu_diff(u):\\n  d = np.where( x > 0, 1, 0)\\n  return y\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYNn0omkegSu"
      },
      "source": [
        "#隠れ層の誤差\n",
        "\"\"\"\n",
        "delta:一個前の誤差（出力層の誤差）\n",
        "w:一個前の重み（出力層の重み）\n",
        "activ:活性化関数の微分\n",
        "\"\"\"\n",
        "def hidden_delta(delta,w,activ):\n",
        "  d = np.zeros((4,12)) #データ数×隠れ層のニューロン数の配列を作成\n",
        "  #d = np.zeros((int(delta),int(w[0])))\n",
        "  for i in range(len(delta)):\n",
        "    for j in range(len(w[0])):\n",
        "      d[i][j] = delta[i]*w[j]*activ[i][j]\n",
        "  return np.array(d)\n",
        "  "
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyTzwOuZ8DZv"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZSLLE7KUrlt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "81915617-540d-4a65-f663-acfbf6c18591"
      },
      "source": [
        "\"\"\"\n",
        "i = 0\n",
        "y = np.zeros(300)\n",
        "\n",
        "N = 4#データ数(ミニバッチ)\n",
        "learning_rate = 0.2#学習率\n",
        "for i in range(300):\n",
        "  \n",
        "  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\n",
        "  target =  np.array([[0],[1],[1],[0]]) #教師\n",
        "  \n",
        "\n",
        "  A1 = np.dot(x,W1)+B1\n",
        "  Z1 = relu(A1)#一層目活性化関数かける\n",
        "  A2 = np.dot(Z1,W2) + B2\n",
        "  Z2 = sigmoid(A2)\n",
        "  #print(\"Z1\")\n",
        "  #print(Z1)\n",
        "  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\n",
        "  \n",
        "  #print(y)\n",
        "\n",
        "  ###出力層の逆伝搬\n",
        "  ##重み\n",
        "  delta = Z2 - target#誤差\n",
        "  #print(Z2)\n",
        "  #print(\"delta\")\n",
        "  #print(delta)\n",
        "  Z1_t = np.transpose(Z1)\n",
        "  #print(Z1_t)\n",
        "  sum_delta = np.dot(Z1_t,delta)\n",
        "  #print(\"sum_delta\")\n",
        "  #print(sum_delta)\n",
        "  \n",
        "  #print(\"delta_out\")\n",
        "  #delta_out　なんか違う\n",
        "  delta_out =(1/N)*sum_delta\n",
        "  #print(\"delta_out\")\n",
        "  #print(delta_out)\n",
        "  \n",
        "  #print(\"W2\")\n",
        "  #print(W2)\n",
        " \n",
        "  W2 = W2 - learning_rate*delta_out\n",
        "  #print(\"W2\")\n",
        "  #print(W2)\n",
        "\n",
        "\n",
        "  ##バイアス\n",
        "  a = np.array([1,1,1,1])\n",
        "  sum_delta_bias = np.dot(a,delta)\n",
        "  delta_out_bias = 1/N*sum_delta_bias\n",
        "  #print(delta_out_bias)\n",
        "  #print(B2)\n",
        "  B2 = B2 - learning_rate*delta_out_bias\n",
        "  #print(\"B2\")\n",
        "  #print(B2)\n",
        "\n",
        "  ###隠れ層の逆伝搬\n",
        "  ##重み\n",
        "  differential_y = relu_diff(Z1)#活性化関数の微分\n",
        "  #print(differential_y)\n",
        "  hid_delta = hidden_delta(delta,W2,differential_y)\n",
        "  #print(hid_delta)\n",
        "  x_t = np.transpose(x)\n",
        "  delta_hidden = 1/N*np.dot(x_t,hid_delta)\n",
        "  W1 = W1 - learning_rate*delta_hidden\n",
        "  #print(\"W1\")\n",
        "  #print(W1)\n",
        "\n",
        "  ##バイアス\n",
        "  a2 = np.array([1,1,1,1])\n",
        "  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\n",
        "  #print(B1)\n",
        "  B1 = B1 - learning_rate*delta_hidden_bias\n",
        "  #print(\"B1\")\n",
        "  #print(B1)\n",
        "\"\"\""
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ni = 0\\ny = np.zeros(300)\\n\\nN = 4#データ数(ミニバッチ)\\nlearning_rate = 0.2#学習率\\nfor i in range(300):\\n  \\n  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\\n  target =  np.array([[0],[1],[1],[0]]) #教師\\n  \\n\\n  A1 = np.dot(x,W1)+B1\\n  Z1 = relu(A1)#一層目活性化関数かける\\n  A2 = np.dot(Z1,W2) + B2\\n  Z2 = sigmoid(A2)\\n  #print(\"Z1\")\\n  #print(Z1)\\n  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\\n  \\n  #print(y)\\n\\n  ###出力層の逆伝搬\\n  ##重み\\n  delta = Z2 - target#誤差\\n  #print(Z2)\\n  #print(\"delta\")\\n  #print(delta)\\n  Z1_t = np.transpose(Z1)\\n  #print(Z1_t)\\n  sum_delta = np.dot(Z1_t,delta)\\n  #print(\"sum_delta\")\\n  #print(sum_delta)\\n  \\n  #print(\"delta_out\")\\n  #delta_out\\u3000なんか違う\\n  delta_out =(1/N)*sum_delta\\n  #print(\"delta_out\")\\n  #print(delta_out)\\n  \\n  #print(\"W2\")\\n  #print(W2)\\n \\n  W2 = W2 - learning_rate*delta_out\\n  #print(\"W2\")\\n  #print(W2)\\n\\n\\n  ##バイアス\\n  a = np.array([1,1,1,1])\\n  sum_delta_bias = np.dot(a,delta)\\n  delta_out_bias = 1/N*sum_delta_bias\\n  #print(delta_out_bias)\\n  #print(B2)\\n  B2 = B2 - learning_rate*delta_out_bias\\n  #print(\"B2\")\\n  #print(B2)\\n\\n  ###隠れ層の逆伝搬\\n  ##重み\\n  differential_y = relu_diff(Z1)#活性化関数の微分\\n  #print(differential_y)\\n  hid_delta = hidden_delta(delta,W2,differential_y)\\n  #print(hid_delta)\\n  x_t = np.transpose(x)\\n  delta_hidden = 1/N*np.dot(x_t,hid_delta)\\n  W1 = W1 - learning_rate*delta_hidden\\n  #print(\"W1\")\\n  #print(W1)\\n\\n  ##バイアス\\n  a2 = np.array([1,1,1,1])\\n  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\\n  #print(B1)\\n  B1 = B1 - learning_rate*delta_hidden_bias\\n  #print(\"B1\")\\n  #print(B1)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "2cjqu25q91LA",
        "outputId": "6fa713ca-15b1-4662-8a70-8be831d8c1d4"
      },
      "source": [
        "\"\"\"\n",
        "i = 0\n",
        "y = np.zeros(100)\n",
        "\n",
        "\n",
        "N = 4#データ数(ミニバッチ)\n",
        "learning_rate = 0.2#学習率\n",
        "pram_b1 = 0.9\n",
        "pram_b2 = 0.999\n",
        "epsiron = 0.00000001\n",
        "alfa = 0.0001\n",
        "m = 0\n",
        "v = 0\n",
        "for i in range(100):\n",
        "  \n",
        "  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\n",
        "  target =  np.array([[0],[1],[1],[0]]) #教師\n",
        "  \n",
        "\n",
        "  A1 = np.dot(x,W1)+B1\n",
        "  Z1 = relu(A1)#一層目活性化関数かける\n",
        "  #print(\"Z1\")\n",
        "  #print(Z1)\n",
        "  A2 = np.dot(Z1,W2) + B2\n",
        "  Z2 = sigmoid(A2)\n",
        "  #print(\"Z2\")\n",
        "  #print(Z2)\n",
        "  #print(\"target\")\n",
        "  #print(target)\n",
        "  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\n",
        "  \n",
        "  #print(y)\n",
        "\n",
        "  ###出力層の逆伝搬\n",
        "  ##重み\n",
        "  delta = Z2 - target#誤差\n",
        "  #print(Z2)\n",
        "  #print(\"delta\")\n",
        "  #print(delta)\n",
        "  Z1_t = np.transpose(Z1)\n",
        "  #print(Z1_t)\n",
        "  sum_delta = np.dot(Z1_t,delta)\n",
        "  #print(\"sum_delta\")\n",
        "  #print(sum_delta)\n",
        "  \n",
        "  #print(\"delta_out\")\n",
        "  #delta_out　なんか違う\n",
        "  delta_out =(1/N)*sum_delta\n",
        "  #print(\"delta_out\")\n",
        "  #print(delta_out)\n",
        "  \n",
        "  print(\"W2\")\n",
        "  print(W2)\n",
        " \n",
        "  m = pram_b1*m + (1-pram_b2)*(delta_out + alfa*W2)\n",
        "  v = pram_b2*v + (1-pram_b2)*(delta_out + alfa*W2)**2\n",
        "  m = m/(1-pram_b1**(i+1))\n",
        "  v = v/(1-pram_b2**(i+1))\n",
        "  W2 = W2 - learning_rate*m/(np.sqrt(v)+epsiron)\n",
        "  print(\"W2\")\n",
        "  print(W2)\n",
        "\n",
        "\n",
        "  ##バイアス\n",
        "  a = np.array([1,1,1,1])\n",
        "  sum_delta_bias = np.dot(a,delta)\n",
        "  delta_out_bias = 1/N*sum_delta_bias\n",
        "  #print(delta_out_bias)\n",
        "  #print(B2)\n",
        "  B2 = B2 - learning_rate*delta_out_bias\n",
        "  #print(\"B2\")\n",
        "  #print(B2)\n",
        "\n",
        "  ###隠れ層の逆伝搬\n",
        "  ##重み\n",
        "  differential_y = relu_diff(Z1)#活性化関数の微分\n",
        "  print(differential_y)\n",
        "  hid_delta = hidden_delta(delta,W2,differential_y)\n",
        "  #print(hid_delta)\n",
        "  x_t = np.transpose(x)\n",
        "  delta_hidden = 1/N*np.dot(x_t,hid_delta)\n",
        "  W1 = W1 - learning_rate*delta_hidden\n",
        "  #print(\"W1\")\n",
        "  #print(W1)\n",
        "\n",
        "  ##バイアス\n",
        "  a2 = np.array([1,1,1,1])\n",
        "  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\n",
        "  #print(B1)\n",
        "  B1 = B1 - learning_rate*delta_hidden_bias\n",
        "  #print(\"B1\")\n",
        "  #print(B1)\n",
        "\"\"\""
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ni = 0\\ny = np.zeros(100)\\n\\n\\nN = 4#データ数(ミニバッチ)\\nlearning_rate = 0.2#学習率\\npram_b1 = 0.9\\npram_b2 = 0.999\\nepsiron = 0.00000001\\nalfa = 0.0001\\nm = 0\\nv = 0\\nfor i in range(100):\\n  \\n  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\\n  target =  np.array([[0],[1],[1],[0]]) #教師\\n  \\n\\n  A1 = np.dot(x,W1)+B1\\n  Z1 = relu(A1)#一層目活性化関数かける\\n  #print(\"Z1\")\\n  #print(Z1)\\n  A2 = np.dot(Z1,W2) + B2\\n  Z2 = sigmoid(A2)\\n  #print(\"Z2\")\\n  #print(Z2)\\n  #print(\"target\")\\n  #print(target)\\n  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\\n  \\n  #print(y)\\n\\n  ###出力層の逆伝搬\\n  ##重み\\n  delta = Z2 - target#誤差\\n  #print(Z2)\\n  #print(\"delta\")\\n  #print(delta)\\n  Z1_t = np.transpose(Z1)\\n  #print(Z1_t)\\n  sum_delta = np.dot(Z1_t,delta)\\n  #print(\"sum_delta\")\\n  #print(sum_delta)\\n  \\n  #print(\"delta_out\")\\n  #delta_out\\u3000なんか違う\\n  delta_out =(1/N)*sum_delta\\n  #print(\"delta_out\")\\n  #print(delta_out)\\n  \\n  print(\"W2\")\\n  print(W2)\\n \\n  m = pram_b1*m + (1-pram_b2)*(delta_out + alfa*W2)\\n  v = pram_b2*v + (1-pram_b2)*(delta_out + alfa*W2)**2\\n  m = m/(1-pram_b1**(i+1))\\n  v = v/(1-pram_b2**(i+1))\\n  W2 = W2 - learning_rate*m/(np.sqrt(v)+epsiron)\\n  print(\"W2\")\\n  print(W2)\\n\\n\\n  ##バイアス\\n  a = np.array([1,1,1,1])\\n  sum_delta_bias = np.dot(a,delta)\\n  delta_out_bias = 1/N*sum_delta_bias\\n  #print(delta_out_bias)\\n  #print(B2)\\n  B2 = B2 - learning_rate*delta_out_bias\\n  #print(\"B2\")\\n  #print(B2)\\n\\n  ###隠れ層の逆伝搬\\n  ##重み\\n  differential_y = relu_diff(Z1)#活性化関数の微分\\n  print(differential_y)\\n  hid_delta = hidden_delta(delta,W2,differential_y)\\n  #print(hid_delta)\\n  x_t = np.transpose(x)\\n  delta_hidden = 1/N*np.dot(x_t,hid_delta)\\n  W1 = W1 - learning_rate*delta_hidden\\n  #print(\"W1\")\\n  #print(W1)\\n\\n  ##バイアス\\n  a2 = np.array([1,1,1,1])\\n  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\\n  #print(B1)\\n  B1 = B1 - learning_rate*delta_hidden_bias\\n  #print(\"B1\")\\n  #print(B1)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKf_MnAfAfF2"
      },
      "source": [
        "\n",
        "i = 0\n",
        "y = np.zeros(100)\n",
        "\n",
        "count = 0\n",
        "\n",
        "N = 4#データ数(ミニバッチ)\n",
        "learning_rate = 0.2#学習率\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "epsiron = 0.00000001\n",
        "alfa = 0.0001\n",
        "mX = np.zeros((12,1))\n",
        "vX = np.zeros((12,1))\n",
        "m = 0\n",
        "v = 0\n",
        "\n",
        "for i in range(100):\n",
        "  \n",
        "  x = np.array([[0,0],[0,1],[1,0],[1,1]])#入力\n",
        "  target =  np.array([[0],[1],[1],[0]]) #教師\n",
        "  \n",
        "\n",
        "  A1 = np.dot(x,W1)+B1\n",
        "  Z1 = relu(A1)#一層目活性化関数かける\n",
        "  #print(\"Z1\")\n",
        "  #print(Z1)\n",
        "  #print(\"B2\")\n",
        "  #print(B2)\n",
        " \n",
        "  \n",
        "  A2 = np.dot(Z1,W2) + B2\n",
        "  Z2 = sigmoid(A2)\n",
        "  #print(\"Z2\")\n",
        "  #print(Z2)\n",
        "  #print(\"target\")\n",
        "  #print(target)\n",
        "  y[i] = cross_entropy_error(Z2,target)#出力層の損失関数\n",
        "  \n",
        "  #print(y)\n",
        "\n",
        "  ###出力層の逆伝搬\n",
        "  ##重み\n",
        "  delta = Z2 - target#誤差\n",
        "  #print(Z2)\n",
        "  #print(\"delta\")\n",
        "  #print(delta)\n",
        "  Z1_t = np.transpose(Z1)\n",
        "  #print(Z1_t)\n",
        "  sum_delta = np.dot(Z1_t,delta)\n",
        "  #print(\"sum_delta\")\n",
        "  #print(sum_delta)\n",
        "  \n",
        "  #print(\"delta_out\")\n",
        "  #delta_out　なんか違う\n",
        "  #delta_out =(1/N)*sum_delta\n",
        "  #print(\"delta_out\")\n",
        "  #print(delta_out)\n",
        "  \n",
        "  #print(\"W2\")\n",
        "  #print(W2)\n",
        "  beta1coef = (1-beta1)/N\n",
        "  beta2coef = (1-beta2)/N/N\n",
        "  \"\"\"\n",
        "  m = beta1*m + beta1coef*(sum_delta + alfa*W2*N)\n",
        "  v = beta2*v + beta2coef*(sum_delta + alfa*W2)*(sum_delta+alfa+W2)\n",
        "  m = beta1*m+beta1coef*sum_delta\n",
        "  v = beta2*v+beta2coef*sum_delta*sum_delta\n",
        "  \"\"\"\n",
        "  \n",
        "  \n",
        "\n",
        "  for q in range(1):\n",
        "    mX[q] = beta1*mX[q] + beta1coef*(sum_delta[q] + alfa*W2[q]*N)\n",
        "    #print(mX[q])\n",
        "    vX[q] = beta2*vX[q] + beta2coef*(sum_delta[q] + alfa*W2[q])*(sum_delta[q]+alfa+W2[q])\n",
        "    m = beta1*m+beta1coef*delta\n",
        "    v = beta2*v+beta2coef*delta*delta\n",
        "  #print(sum_delta)\n",
        "  #print( beta1*m[p][q] + beta1coef*(sum_delta[p][q] + alfa*W2[p][q]*N))\n",
        "  epoch = count/(2*N+1)  \n",
        "  sqbeta = np.sqrt((1-beta2**(epoch+1)))\n",
        "  learning_rate2 = learning_rate/(1-beta1**(epoch+1))*sqbeta\n",
        "  epsilon2 = sqbeta * epsiron\n",
        "\n",
        "  q = 0\n",
        "  for p in range(11):\n",
        "    W2[q] = W2[q] - learning_rate2*mX[q]/(np.sqrt(vX[q]))+epsilon2\n",
        "    B2 = B2 - learning_rate2*m/(np.sqrt(v)+epsilon2)\n",
        "  \n",
        "\n",
        "  #print(\"m\")\n",
        "  #print(m)\n",
        "\n",
        "\n",
        "  ##バイアス\n",
        "\n",
        "  #print(delta_out_bias)\n",
        "  #print(B2)\n",
        "  \n",
        "  #B2 = B2 - learning_rate2*m[0]/(np.sqrt(v[0])+epsilon2)\n",
        "  \n",
        "  ###隠れ層の逆伝搬\n",
        "  ##重み\n",
        "  differential_y = relu_diff(Z1)#活性化関数の微分\n",
        "  #print(\"Z1\")\n",
        "  #print(Z1)\n",
        "  #print(\"differential_y\")  \n",
        "  #print(differential_y)\n",
        "  hid_delta = hidden_delta(delta,W2,differential_y)\n",
        "  #print(hid_delta)\n",
        "  x_t = np.transpose(x)\n",
        "  delta_hidden = 1/N*np.dot(x_t,hid_delta)\n",
        "  W1 = W1 - learning_rate*delta_hidden\n",
        "  #print(\"W1\")\n",
        "  #print(W1)\n",
        "\n",
        "  ##バイアス\n",
        "  a2 = np.array([1,1,1,1])\n",
        "  delta_hidden_bias = 1/N*np.dot(a2,hid_delta)\n",
        "  #print(B1)\n",
        "  B1 = B1 - learning_rate*delta_hidden_bias\n",
        "  #print(\"B1\")\n",
        "  #print(B1)\n",
        "  count = count +1"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4TalPJTI39Oy",
        "outputId": "239285b4-6843-4ed8-a91a-f5eff1123075"
      },
      "source": [
        "p = np.arange(100)\n",
        "plt.scatter(p, y, c='b', label='loss_data')\n",
        "#plt.legend()\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BZlWMYObD1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fccb025-5457-4218-a244-a8e1fc7d486f"
      },
      "source": [
        "A1 = np.dot(x,W1) +B1\n",
        "Z1 = relu(A1)#一層目活性化関数かける\n",
        "\n",
        "\n",
        "A2 = np.dot(Z1,W2)+B2\n",
        "Z22 = sigmoid(A2)\n",
        "\n",
        "delta = Z2 - target#誤差\n",
        "#print(delta)\n",
        "print(Z2)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.02160101e-11]\n",
            " [1.00000000e+00]\n",
            " [9.99999999e-01]\n",
            " [1.11094190e-11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUgxJbD0o_zy"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxGiQAg-o_ob"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4poqP4Loo_bw"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui7jl1ERpD2h"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrPIQcknpGdf"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}